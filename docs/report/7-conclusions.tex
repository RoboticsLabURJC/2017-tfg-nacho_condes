\chapter{Conclusions}
\section{Conclusions}
	This final chapter will be devoted to revisit the  proposed objectives. They could be summarized in a central purpose: \emph{enriching the JdeRobot framework with new tools and applications focused on deep learning}. With a complete coverage of the performed tasks, as it has been described on the previous pages, we can contrast what has been achieved on each milestone which was established along the way, in order to accomplish incremental achievements.\\
	
	\begin{description}
		\item[Classification tool for processing live images.] \hfill
			\vspace{0.2in} \\
			The first objective was to upgrade the scope for an existing JdeRobot tool, \texttt{DigitClassifier}, which was designed to perform \emph{classification} tasks using \emph{deep learning} techniques.\\
			
			Its functionality was extended to support the \emph{deep learning} framework TensorFlow, implementing and training networks on our own. This has allowed to achieve initial knowledge about the framework, and enough skills to move towards more complex tasks.\\
			
			In light of the excellent achieved performance, the brand new TensorFlow implementation and the previous one (made with the Keras framework) were merged into an \emph{official JdeRobot} component\footnote{\url{https://github.com/JdeRobot/dl-digitclassifier}}, capable of commuting between both frameworks.
		
		\item[Neural detection tool for live images.] \hfill
			\vspace{0.2in} \\		
			After having accomplished a basic domain on \emph{deep learning} with \emph{classification} tasks, we tackled a more ambitious milestone: \emph{detecting objects on a real-time operation}. There was no previous reference in the JdeRobot framework.\\
			
			The process of training a detection network was ruled out of the scope of this project, so we addressed the detection task using publicly available \emph{pretrained networks}. So, we developed a wrapping of TensorFlow environment to \emph{abstract} the model (architecture, dataset on which it was trained, output format, etc.), and moved the neural network processing to a \emph{GPU environment} (to achieve the optimum predicting rate for a real-time operation). This remarkably efficient detection framework was demonstrated to be capable of real-time processing, so we have developed an entire node, \texttt{ObjectDetector}, to visually perform this task on an \emph{incoming image stream} (abstracting the source).\\
			
			Hence, the final result  has been a node displaying the raw current image, and aside the same one with the detected objects overlaid, indicating their location making use of \emph{bounding boxes}, in addition to the estimated \emph{class} for the object, and the \emph{score} (standing for the reliability level that estimation has).\\
			
			Once more, the excellent performance on real-time (using detectors with a SSD architecture for instance) has driven us to integrate this node\footnote{\url{https://github.com/JdeRobot/dl-objectdetector}} in the JdeRobot framework as well, developing another module to do the same for Keras network models. This has enabled us again to be able to abstract the frameworks, and toggle one of them through the YML file. In addition, this has given us the capability of \emph{benchmarking} new models, as they can be transparently loaded into the created environment, and begin making inferences on real time.
		
		\item[Tracking and following robot behavior using deep learning detection] \hfill
			\vspace{0.2in} \\
			The two previous milestones allowed us to accomplish \emph{state-of-the-art} purposes in the \emph{Computer Vision} field. As the final research objective, we have considered an \emph{actuation} system which uses a powerful \emph{neural network} to accomplish an robust visual perception. In order to overlap our research with the prosperous field of \emph{robotics}, we have developed a component capable of \emph{following} a specific person (\emph{mom}). This has been achieved using concepts like a \emph{PID} controller feedback control, and case-based control.\\
			
	\end{description}
	
	All these achievements have contributed the JdeRobot framework with an upgraded tool (\emph{DigitClassifier}, which now offers support for both Keras and TensorFlow), a brand new tool (\emph{ObjectDetector}), and a new robotics application (\emph{FollowPerson}, capable of chasing a person with excellent results). These new resources are focused on providing real time operation. In addition, all the underlying software created (the \emph{TensorFlow} and \emph{Keras} generic network loaders) can be of great help for future applications.\\
	
	Beyond the technical contents, this project has allowed an interested person in \emph{deep learning} to learn about a cornucopia of concepts and experience. A while ago, when it was decided to evolve towards creating a reactive behavioral, it was motivating to make the most of a possible synergy between two different fields of knowledge, as \emph{deep learning} and \emph{robotics} are.\\
	
	In the professional point of view, it has been essential to acquire further skills about \emph{version control systems}, as Git. This can be an important benefit, as every development project in a corporate environment makes use of this kind of controls.

\section{Future lines}
	The proposed milestones on this project have been successfully achieved using a useful and innovative tool as \emph{deep learning}. Furthermore, it opens some interesting doors to future research or improvements:
	
	\begin{itemize}
		\item \emph{Upgrade DigitClassifier:} for now, this component looks for the digit in a fixed window inside the input image (the central square). Another module could be implemented to perform a \emph{character detection} in the whole image, maybe an OCR number detector.
		
		\item \emph{Translate the Python nodes to a compiled and fast language:} one of the main handicaps of Python is the fact that it is an interpreted language (much slower than a compiled one). So, a \emph{translation} to a lower level language as \texttt{C++} would be very interesting, as it is a widely supported language in this framework, and there are already very efficient \emph{deep learning} implementations on it (as \emph{Darknet/YOLO}).
		
		\item \emph{Use a deep learning face detector in FollowPerson:} the main advantage of the \emph{deep learning} systems is the robustness on their operation, so a facial detection system implemented with this technology could be a powerful resource to perform a facial detection/validation in harshly lightened environments.
		
		\item \emph{Multimodal person detection/tracking:} some extra functionality could be squeezed from a RGBD sensor, like \emph{tracking a person in complete darkness}. As \emph{deep learning} systems offer good results distinguishing a person silhouette, we could perform people detection on a depth image.
		
		
		\item \emph{Add a navigation algorithm to FollowPerson:} the movement commands sent to the Turtlebot are now decided taking into account only the relative position of the person from the robot. However, as the robot incorporates a laser sensor, we can add an \emph{obstacle avoidance} system, in order to perform a non-blind navigation towards the person.
	\end{itemize}
