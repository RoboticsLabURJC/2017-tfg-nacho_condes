%%%%%%%%%%%%%%%%%%%% author.tex %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
% sample root file for your "contribution" to a proceedings volume
%
% Use this file as a template for your own input.
%
%%%%%%%%%%%%%%%% Springer %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass{svproc}
%
% RECOMMENDED %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%

% to typeset URLs, URIs, and DOIs
\usepackage{url}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\def\UrlFont{\rmfamily}

\begin{document}
\mainmatter              % start of a contribution
%
\title{Person Following Robot Behavior Using Deep Learning}
%
%
\author{Ignacio Condés\inst{1} \and José María Cañas\inst{2}}
%

%
\institute{Universidad Rey Juan Carlos,
	\email{ignacio.condes.m@gmail.com},
	\and
Universidad Rey Juan Carlos, \email{jmplaza@gsyc.es}}

\maketitle              % typeset the title of the contribution

\begin{abstract}
The proposed following behavior combines a \emph{perception} and a \emph{control} module. Perception module addresses the person detection on images using a pretrained TensorFlow SSD \emph{Convolutional Neural Network}. It provides \emph{robustness} over traditional methods, although care has to be put on not losing real-time operation. A \emph{person tracker filter} has been included to alleviate the effect of false positives/negatives. It also extracts faces, which are also analyzed by a \emph{FaceNet} CNN to reidentify the tracked individual. This perception module tells which person in the image has to be followed, even on poorly lightened scenarios. It is combined with depth readings to obtain the relative position of the person. The control module implements a case-based \emph{PID} controller for a reactive smooth response, moving the robot towards the target person. The entire system has been experimentally validated\footnote{\url{https://jderobot.org/Naxvm-tfg}} on a real Turtlebot2 robot, with an Asus Xtion RGBD camera.
% We would like to encourage you to list your keywords within
% the abstract section using the \keywords{...} command.
\keywords{Computer Vision, neural networks, deep learning, robotic behavior}
\end{abstract}
%

%  ---- Intro ----
\input{1-intro}

% ---- State of the art ----
\input{2-stateoftheart}

% ---- Infrastructure ----
\input{3-infrastructure}

% ---- Perception module ----
\input{4-perception}

% ---- Actuation module ----
\input{5-actuation}

% ---- Experiments ----
\input{6-experiments}

% ---- Conclusions ----
\input{7-conclusions}








% ---- Bibliography ----
%
\begin{thebibliography}{6}
%

\bibitem {rocapal}
Calvo, R.: Comportamiento sigue persona con visión direccional, 2004.

\bibitem {ssd}
Lui, W., Anguelov, D., Erhan, D., et al. SSD: Single-Shot Multibox Detector. \emph{CoRR}, abs/1512.02325, 2015.

\bibitem {viola-jones}
Viola, P., Jones, M. Rapid object detection using a boosted cascade of simple features. In \emph{Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001}, volume 1, pages I-511-I-518 vol.1, 2001.

\bibitem{facenet}
Schroff, F., Kalenichenko, D., Philbin, J. \emph{FaceNet}: A unified embedding for face recognition and clustering. \emph{CoRR}, abs/1503.038032, 2015.

\bibitem{pid-controller}
Åström, KJ., Murray, RM. Feedback Systems: An Introduction for Scientists and Engineers, 2004.

\end{thebibliography}
\end{document}
