\documentclass[11pt, a4paper]{svproc}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{multicol}
\usepackage{footmisc}

\title{Person following robot behavior using Deep Learning}
\author{Ignacio Condés
		\and José María Cañas}
\institute{Universidad Rey Juan Carlos}

\begin{document}
	\maketitle
	
	\begin{abstract}
		The proposed following behavior has been developed combining a \emph{perception module} and a \emph{controller module}.\\
		
		The perception module addresses person detection using a \emph{Convolutional Neural Network} to process the incoming images. The main benefit over traditional methods is the \emph{robustness} that deep learning can yield, but an eye must be kept on not losing a real-time operation.\\
		
		This scheme uses a pretrained SSD person detection CNN we have deployed on TensorFlow. In order to increase the robustness of the perception system, we have also implemented a \emph{person tracker} that eliminates the effect of false positives/negatives. The perception module also has a \emph{face detection} block (using \emph{Haar Cascade} detectors). The extracted faces are then analyzed by a \emph{siamese network}, in order to reidentify the tracked individual person.
		
		This perception pipeline tells which of the persons in the image is the one to follow, even on poorly lightened scenarios. This information is combined with depth readings, to obtain a fine estimation of the relative position of the person.\\
		
		The controller module implements a case-based \emph{PID} controller for a reactive smooth response, moving the robot towards the objective person.
		
		
		
		The entire system has been experimentally validated on a real Turtlebot robot, with an Asus Xtion conventional RGBD camera.
	\end{abstract}

	
	
\end{document}