\section{Perception Module}

This is the first component of the developed system. As it name indicates, it is responsible for apprehend the incoming images from the sensor (RGB and depth) images, and generate a significant output to be interpreted by the actuation module. Its structure follows a certain pipeline along the images, which will be analyzed next.


\subsection{Object Detection}

On first place, the incoming RGB images are passed through an \emph{object detection} module. This module is powered by a CNN, which has a special architecture designed for this purpose: SSD (\emph{Single-Shot Multibox Detector}). This kind of detection technique stands out by its prediction speed, because \emph{it performs a single feed-forward pass} of the image through the network, unlike the rest of \emph{state-of-the-art} techniques (which are consequently much slower, AS CAN BE SEEN ON [tabla experimentos object detector]).\\


IMAGEN ESTRUCTURA RED (5.6 tfg)
This neural architecture is formed putting together a succession of blocks:

\begin{enumerate}
	\item \emph{Preprocessing:} as this kind of neural networks work with a fixed image shape (300$\times$300 px in this case, the most typical one among other SSD implementations).\\
	
	\item \emph{Feature Extraction:} a first group of layers (\emph{base network}) deals the \emph{feature extraction} part. As it is composed by a concatenation of \emph{convolutional} layers, the resulting activation maps are gradually smaller and deeper. So, 6 intermediate sets, composed by activation maps of a certain depth are extracted from this concatenation, with progressive sizes (suitable for different objects shapes). This way, we obtain the 6 activation maps reflected on the Table TABLA PAG 55 TFG.
	
	\item \emph{Box Prediction:} later, on a parallel way for each set, the activation maps are traversed, generating \emph{prior} boxes on each point of them, with different aspect ratios. These \emph{priors} are convolved with small filters, which output \emph{adjustments} for each box, and \emph{softmaxed} confidences for each of the classes that the network knows. IMAGEN PERRO GATO
	
	\item \emph{Postprocessing:} it combines the detections of each of the 6 sets, only retaining the most confident detections (\emph{Non-Maximum Supression}), and adjusting and scaling the obtained bounding boxes to the original image shape. 
\end{enumerate}

This system provides an accurate and efficient object detection, returning for each processed image:

\begin{itemize}
	\item \emph{Classes:} the detected classes (person, cell phone, airplane, dog \dots) inferred for each detected object.
	
	\item \emph{Scores:} the confidence $\in [0,1]$ the network has on each object belonging to the decided class.
	
	\item \emph{Boxes:} the coordinates of the rectangular \emph{bounding box} which wraps the detected object, expressed as the coordinates of two opposite corners of it.
\end{itemize}

However, our system only retains those detection corresponding to \emph{persons}, as it is what we are interested to follow.\\


Hence, this results on a light \emph{person detection}, perfectly capable to work on a real-time operation on a standard level hardware. Our implementation is capable to handle different network models and architectures on a \emph{plug and play} model, just with the model file (in the specific TensorFlow \texttt{.pb} format).



\subsection{Face detection}

Once we have detected the existing persons on the image, we will look for their faces, in order to know whether any of them corresponds to the person to follow. To do so, we will perform \emph{face reidentification}, which needs in first place to detect each person face. To do so, we implement the classical Viola and Jones [31 tfg] face detection algorithm. This algorithm, which comprises \emph{Haar} features (Fig. --), is a simple algebraic method which takes advantage of the typical illumination pattern of a face (due to its physical shape) to detect promising regions of the input image to contain a face. This image is divided into \emph{regions}, which are passed through a \emph{cascade} of tests, where the non-compliant regions are immediately discarded. The accepted ones pass to a slightly more complex feature each time, and the regions which pass all the features are supposed to contain a face. This progressive region dismiss makes it an efficient algorithm, capable of run simultaneously with the rest of processes. This entire process is performed with an OpenCV\footnote{Open source image processing library.} method.\\

As we already knew where the detected persons are in the image, this face detection process is only performed inside the persons bounding boxes.



\subsection{Face reidentification (\emph{FaceNet})}

If it is achieved to find 










