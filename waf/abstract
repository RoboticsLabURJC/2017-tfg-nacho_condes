The proposed following behavior has been developed combining a perception module and a controller module.
The perception module addresses person detection using a Convolutional
Neural Network to process the incoming images. The main benefit over
traditional methods is the robustness that deep learning can yield, but
an eye must be kept on not losing a real-time operation.
This scheme uses a pretrained SSD person detection CNN we have deployed on TensorFlow. In order to increase the robustness of the perception system, we have also implemented a person tracker that eliminates
the effect of false positives/negatives. The perception module also has
a face detection block (using Haar Cascade detectors). The extracted
faces are then analyzed by a siamese network, in order to reidentify the
tracked individual person.
This perception pipeline tells which of the persons in the image is the
one to follow, even on poorly lightened scenarios. This information is
combined with depth readings, to obtain a fine estimation of the relative
position of the person.
The controller module implements a case-based PID controller for a reactive smooth response, moving the robot towards the objective person.
The entire system has been experimentally validated on a real Turtlebot
robot, with an Asus Xtion conventional RGBD camera.
