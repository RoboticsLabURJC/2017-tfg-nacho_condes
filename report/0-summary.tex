\chapter*{Summary}
	Nowadays, continuous improvements on Computer Science allow to address more complex tasks than traditionally. So, we can begin to artificially handle more \emph{human} tasks, which are performed on a more efficient way when the processing structure is modeled \emph{emulating human brain}. This field of study is covered by \emph{deep learning}, which particularly in the Computer Vision field makes the difference between a exhausting analysis of \emph{designed} features (which can be susceptible to environmental transformations or distortions), and \emph{automatically} extract abstract features, allowing a \emph{robust} operation, which can be executed on a  \emph{real time} manner.\\
	
	
	On the other hand \emph{robotics}, gradually more present in daily life, is more accessible, compatible and interoperable. This leads into a faster deployment of robots: not so long ago we only had huge, complex and not practical robots on production lines. Now we have autonomous vacuum cleaners perfectly able to clean our house and go back to its dock, at perfectly affordable prices for the vast majority of people.\\
	
	
	There is a really interesting \emph{synergy} between these two fields, which allow to combine the \emph{perception} skills that a \emph{deep learning} system can achieve, with the wide variety of physical \emph{responses} that a robot can perform.\\
	
	
	In this work, focused on introducing new \emph{deep learning} Computer Vision applications in the academics and research platform JdeRobot, three real-time components have been developed, making use of \emph{neural networks}: a \emph{digit classifier}, a generic \emph{object detector}, and a \emph{person following component}, which also incorporates a \emph{reactive behavioral to follow a specific person}. This is achieved combining an RGBD sensor, detection and facial analysis respective neural networks, and a robot equipped with wheels.